{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d2fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dcdedc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\om prakash yadav\\appdata\\roaming\\python\\python311\\site-packages (4.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\om prakash yadav\\appdata\\roaming\\python\\python311\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\om prakash yadav\\appdata\\roaming\\python\\python311\\site-packages (from webdriver-manager) (1.0.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\om prakash yadav\\appdata\\roaming\\python\\python311\\site-packages (from requests->webdriver-manager) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f5e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf9fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selenium 4\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "chrome_options = Options()\n",
    "chrome_options.accept_untrusted_certs = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c45d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db27ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32a5fd95",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 193] %1 is not a valid Win32 application",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m driver \u001b[38;5;241m=\u001b[39m webdriver\u001b[38;5;241m.\u001b[39mChrome(service\u001b[38;5;241m=\u001b[39mChromeService(ChromeDriverManager()\u001b[38;5;241m.\u001b[39minstall()),options\u001b[38;5;241m=\u001b[39mchrome_options)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\chrome\\webdriver.py:45\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[1;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     42\u001b[0m service \u001b[38;5;241m=\u001b[39m service \u001b[38;5;28;01mif\u001b[39;00m service \u001b[38;5;28;01melse\u001b[39;00m Service()\n\u001b[0;32m     43\u001b[0m options \u001b[38;5;241m=\u001b[39m options \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;28;01melse\u001b[39;00m Options()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     46\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mDesiredCapabilities\u001b[38;5;241m.\u001b[39mCHROME[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrowserName\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     47\u001b[0m     vendor_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoog\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     48\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m     49\u001b[0m     service\u001b[38;5;241m=\u001b[39mservice,\n\u001b[0;32m     50\u001b[0m     keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive,\n\u001b[0;32m     51\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\chromium\\webdriver.py:55\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[1;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[0;32m     52\u001b[0m     options\u001b[38;5;241m.\u001b[39mbrowser_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m finder\u001b[38;5;241m.\u001b[39mget_driver_path()\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m     57\u001b[0m executor \u001b[38;5;241m=\u001b[39m ChromiumRemoteConnection(\n\u001b[0;32m     58\u001b[0m     remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[0;32m     59\u001b[0m     browser_name\u001b[38;5;241m=\u001b[39mbrowser_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     ignore_proxy\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39m_ignore_local_proxy,\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\common\\service.py:98\u001b[0m, in \u001b[0;36mService.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Starts the Service.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[0;32m     94\u001b[0m \u001b[38;5;124;03m    :Exceptions:\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m     - WebDriverException : Raised either when it can't start the service\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m       or when it can't connect to the service\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_process(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path)\n\u001b[0;32m    100\u001b[0m     count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\selenium\\webdriver\\common\\service.py:208\u001b[0m, in \u001b[0;36mService._start_process\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    205\u001b[0m         start_info\u001b[38;5;241m.\u001b[39mdwFlags \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mCREATE_NEW_CONSOLE \u001b[38;5;241m|\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mSTARTF_USESHOWWINDOW\n\u001b[0;32m    206\u001b[0m         start_info\u001b[38;5;241m.\u001b[39mwShowWindow \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mSW_HIDE\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(\n\u001b[0;32m    209\u001b[0m         cmd,\n\u001b[0;32m    210\u001b[0m         env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv,\n\u001b[0;32m    211\u001b[0m         close_fds\u001b[38;5;241m=\u001b[39mclose_file_descriptors,\n\u001b[0;32m    212\u001b[0m         stdout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_output,\n\u001b[0;32m    213\u001b[0m         stderr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_output,\n\u001b[0;32m    214\u001b[0m         stdin\u001b[38;5;241m=\u001b[39mPIPE,\n\u001b[0;32m    215\u001b[0m         creationflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreation_flags,\n\u001b[0;32m    216\u001b[0m         startupinfo\u001b[38;5;241m=\u001b[39mstart_info,\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopen_kw,\n\u001b[0;32m    218\u001b[0m     )\n\u001b[0;32m    219\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarted executable: `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m` in a child process with pid: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to output \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_output,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[0;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 193] %1 is not a valid Win32 application"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()),options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03625fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'driver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m driver\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://play.google.com/store/apps/details?id=com.dibd.bhashini&hl=en_IN&pli=1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m driver\u001b[38;5;241m.\u001b[39mmaximize_window()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'driver' is not defined"
     ]
    }
   ],
   "source": [
    "driver.get(\"https://play.google.com/store/apps/details?id=com.dibd.bhashini&hl=en_IN&pli=1\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1033a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show all reviews\n",
    "\n",
    "all_reviews = driver.find_element(By.XPATH,\"//html/body/c-wiz[2]/div/div/div[1]/div/div[2]/div/div[1]/div[1]/c-wiz[5]/section/div/div[2]/div[5]/div/div/button/span\")\n",
    "all_reviews.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a47de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//html/body/div[5]/div[2]/div\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f78669",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostRelevant = driver.find_element(By.XPATH,\"//html/body/div[5]/div[2]/div/div/div/div/div[2]/div[1]/div[1]/div/div/div/div[2]/div[2]/span[2]\")\n",
    "mostRelevant.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df6b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu2 = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d07b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_newest=driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div[2]/div/div/span[2]/div[2]/div[2]\")\n",
    "select_newest.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4054ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_to_bottom(i,k,n):\n",
    "    \n",
    "    while i < k:\n",
    "            # Wait for the element to be present on the page\n",
    "            element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, \"//html/body/div[5]/div[2]/div/div/div/div/div[2]/div/div[2]/div[{0}]\".format(i))))\n",
    "        \n",
    "            # Scroll into view using JavaScript\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView()\", element)\n",
    "            time.sleep(1)\n",
    "        \n",
    "            i += n\n",
    "            print (i)\n",
    "            \n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c50c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroller(n):\n",
    "    length = 0\n",
    "    k=0\n",
    "    i=1\n",
    "    while i>0:\n",
    "        try:\n",
    "            k+=200\n",
    "            length = scroll_to_bottom(i,k,n)\n",
    "            i+=200\n",
    "        \n",
    "        except TimeoutException:\n",
    "            break\n",
    "            \n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = scroller(19)\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "username=[]\n",
    "rating=[]\n",
    "datee=[]\n",
    "content=[]\n",
    "helpful=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd72c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_content(length):\n",
    "    \n",
    "    for i in range(1,length):\n",
    "        try:\n",
    "            name = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div/div[2]/div[{0}]/header/div[1]/div[1]/div\".format(i))\n",
    "            name_text = name.text\n",
    "        except:\n",
    "            name_text=\"\"\n",
    "        try:\n",
    "            element_with_aria_label = driver.find_element(By.XPATH,\"//div[{0}]/header/div[2]/div[@aria-label]\".format(i))\n",
    "\n",
    "            rating_text = element_with_aria_label.get_attribute('aria-label')\n",
    "\n",
    "        except:\n",
    "            rating_text=\"\"\n",
    "        try:\n",
    "            date = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div/div[2]/div[{0}]/header/div[2]/span\".format(i))\n",
    "            date_text=date.text\n",
    "        except:\n",
    "            date_text=\"\"\n",
    "        try:\n",
    "            review = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div/div[2]/div[{0}]/div[1]\".format(i))\n",
    "            review_text=review.text\n",
    "        except:\n",
    "            review_text=\"\"\n",
    "        try:\n",
    "            helpful_text = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div/div[2]/div[{0}]/div[2]\".format(i))\n",
    "            helpful_text=helpful_text.get_attribute('data-original-thumbs-up-count')\n",
    "        except:\n",
    "            helpful_text=\"\"\n",
    "\n",
    "        username.append(name_text)\n",
    "        rating.append(rating_text)\n",
    "        datee.append(date_text)\n",
    "        content.append(review_text)\n",
    "        helpful.append(helpful_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ee75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_content(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df395403",
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_click = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div[1]/div[1]/div/div/div/div[1]\")\n",
    "phone_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8509dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu2 = driver.find_element(By.XPATH,\"//html/body/div[5]/div[2]/div/div/div/div/div[2]/div[2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d7dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablet = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div[2]/div/div/span[2]/div[3]/div[2]\")\n",
    "tablet.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostRelevant = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div[1]/div[1]/div/div/div/div[2]/div[2]/span[2]\")\n",
    "mostRelevant.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9bd7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div[2]/div/div\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "newest = driver.find_element(By.XPATH,\"/html/body/div[5]/div[2]/div/div/div/div/div[2]/div[2]/div/div/span[2]/div[2]/div[2]\")\n",
    "newest.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc29eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scroller(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_content(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8928206",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={\"Date\":datee,\"Username\":username,\"Content\":content,\"Rating\":rating,\"Helped\":helpful}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51618ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ef9856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22871f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25109821",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe9c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(new_data.Date[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5e08ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Date'] = pd.to_datetime(new_data['Date'])\n",
    "\n",
    "print (type(new_data.Date[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d277845",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.sort_values( by='Date', ascending = False )\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8bfc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46e20e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (type(new_data.Rating[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f5ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numeric_rating(rating):\n",
    "    # Use regular expression to find numbers\n",
    "    match = re.search(r'\\d+(\\.\\d+)?', rating)\n",
    "    if match:\n",
    "        return float(match.group())\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "new_data['Rating'] = new_data['Rating'].apply(extract_numeric_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11021eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c604b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install fasttext--wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "def detect_language_fasttext(text):\n",
    "    try:\n",
    "        model = fasttext.load_model(r\"C:\\Users\\Om Prakash Yadav\\Downloads\\lid.176.bin\")\n",
    "        lang_detected = model.predict(text)\n",
    "        print (lang_detected)\n",
    "        return lang_detected[0][0].replace('__label__', '')\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a88d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Language'] = new_data['Content'].apply(detect_language_fasttext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4872b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae304c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_counts = new_data['Language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_percentages = (language_counts / len(new_data)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f92968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "language_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb3b388",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv(r\"C:\\Users\\Om Prakash Yadav\\OneDrive\\Desktop\\Reviews Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc86d3",
   "metadata": {},
   "source": [
    "## IndicBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f98a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets torch scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = new_data\n",
    "\n",
    "# Neutral: 1\n",
    "# Negative: 0\n",
    "# Positive : 2\n",
    "\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(df['Rating'].value_counts())\n",
    "\n",
    "def map_sentiment(stars_received):\n",
    "    if stars_received <= 2:\n",
    "        return 0\n",
    "    elif stars_received == 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "df['Sentiment'] = [ map_sentiment(x) for x in df['Rating']]\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.remove_columns([\"Date\", \"Username\", \"Rating\", \"Helped\", \"Language\"])\n",
    "dataset = dataset.rename_column(\"Sentiment\", \"label\")\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']\n",
    "\n",
    "#Extract features using the pre-trained IndicBERT model\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "model_name = \"ai4bharat/indic-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def extract_features(text_list):\n",
    "    inputs = tokenizer(text_list, padding=True, max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "train_features = extract_features(train_dataset['Content'])\n",
    "test_features = extract_features(test_dataset['Content'])\n",
    "\n",
    "#Training a simple classifier on the extracted features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(train_features, train_dataset['label'])\n",
    "\n",
    "#Evaluate the classifier's performance\n",
    "test_predictions = clf.predict(test_features)\n",
    "accuracy = accuracy_score(test_dataset['label'], test_predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "num_reviews = df.shape\n",
    "rating_stats = df['Rating'].describe()\n",
    "sentiment_counts = df['Sentiment'].value_counts()\n",
    "helpful_stats = new_data['Helped'].describe()\n",
    "\n",
    "# User Analysis\n",
    "num_users = df['Username'].nunique()\n",
    "top_contributors = df['Username'].value_counts().head(10)\n",
    "avg_rating = df['Rating'].mean()\n",
    "avg_sentiment = df['Sentiment'].mean()\n",
    "\n",
    "# Language Analysis\n",
    "num_languages = df['Language'].nunique()\n",
    "language_counts = df['Language'].value_counts()\n",
    "avg_rating_by_language = df.groupby('Language')['Rating'].mean()\n",
    "avg_sentiment_by_language = df.groupby('Language')['Sentiment'].mean()\n",
    "\n",
    "print(f\"Number of reviews: {num_reviews}\\n\")\n",
    "print(\"Rating Statistics:\")\n",
    "print(rating_stats, \"\\n\")\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(sentiment_counts, \"\\n\")\n",
    "print(\"Helpful Votes Statistics:\")\n",
    "print(helpful_stats, \"\\n\")\n",
    "print(f\"Number of unique users: {num_users}\\n\")\n",
    "print(\"Top Contributors:\")\n",
    "print(top_contributors, \"\\n\")\n",
    "print(\"Average Rating:\")\n",
    "print(avg_rating, \"\\n\")\n",
    "print(\"Average Sentiment:\")\n",
    "print(avg_sentiment, \"\\n\")\n",
    "print(f\"Number of Languages: {num_languages}\\n\")\n",
    "print(\"Language Distribution:\")\n",
    "print(language_counts, \"\\n\")\n",
    "print(\"Average Rating by Language:\")\n",
    "print(avg_rating_by_language, \"\\n\")\n",
    "print(\"Average Sentiment by Language:\")\n",
    "print(avg_sentiment_by_language, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Distribution of Ratings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Rating', data=df, palette='viridis')\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d10b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Sentiments\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Sentiment', data=df, palette='coolwarm')\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e624c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Languages\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='Language', data=df, palette='Set3')\n",
    "plt.title('Distribution of Languages')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d500ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment vs Rating\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Rating', y='Sentiment', data=df)\n",
    "plt.title('Sentiment vs Rating')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baaf4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating by Language\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Language', y='Rating', data=df, palette='Pastel1')\n",
    "plt.title('Rating by Language')\n",
    "plt.xlabel('Language')\n",
    "plt.ylabel('Rating')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpful Votes by Rating\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Rating', y='Helped', data=df, palette='viridis')\n",
    "plt.title('Helpful Votes by Rating')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Helpful Votes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2c838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating and Sentiment over Time\n",
    "plt.figure(figsize=(14, 8))\n",
    "df.groupby('Date').mean()['Rating'].plot(color='green', label='Rating')\n",
    "df.groupby('Date').mean()['Sentiment'].plot(color='blue', label='Sentiment')\n",
    "plt.title('Average Rating and Sentiment Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud for Review Content\n",
    "!pip install wordcloud\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "all_text = ' '.join(df['Content'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Word Cloud for Review Content')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "corr_matrix = df['Sentiment'].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde45c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4878f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot most frequent terms\n",
    "def freq_words(x, terms = 30):\n",
    "  all_words = ' '.join([text for text in x])\n",
    "  all_words = all_words.split()\n",
    "\n",
    "  fdist = FreqDist(all_words)\n",
    "  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())})\n",
    "\n",
    "  # selecting top 20 most frequent words\n",
    "  d = words_df.nlargest(columns=\"count\", n = terms) \n",
    "  plt.figure(figsize=(20,5))\n",
    "  ax = sns.barplot(data=d, x= \"word\", y = \"count\")\n",
    "  ax.set(ylabel = 'Count')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4e85a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove unwanted characters, numbers and symbols\n",
    "df['reviewText'] = df['Content'].str.replace(\"[^a-zA-Z#]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240af83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(rev):\n",
    "    rev_new = \" \".join([i for i in rev if i not in stop_words])\n",
    "    return rev_new\n",
    "\n",
    "# remove short words (length < 3)\n",
    "df['reviewText'] = df['reviewText'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>2]))\n",
    "\n",
    "# remove stopwords from the text\n",
    "reviews = [remove_stopwords(r.split()) for r in df['reviewText']]\n",
    "\n",
    "# make entire text lowercase\n",
    "reviews = [r.lower() for r in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be22487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_words(reviews, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b185886",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatization(texts, tags=['NOUN', 'ADJ']): # filter noun and adjective\n",
    "       output = []\n",
    "       for sent in texts:\n",
    "             doc = nlp(\" \".join(sent)) \n",
    "             output.append([token.lemma_ for token in doc if token.pos_ in tags])\n",
    "       return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90001375",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenization\n",
    "\n",
    "tokenized_reviews = pd.Series(reviews).apply(lambda x: x.split())\n",
    "print(tokenized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e861bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Om Prakash Yadav\\Downloads\\final_stopwords.txt\", encoding='utf-8') as f:\n",
    "    hindi_stopwords = set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the list and remove stopwords\n",
    "\n",
    "filtered_reviews = [\n",
    "    [word for word in review if word not in hindi_stopwords]\n",
    "    for review in tokenized_reviews\n",
    "]\n",
    "\n",
    "filtered_texts = [' '.join(review) for review in filtered_reviews]\n",
    "\n",
    "print(filtered_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d992d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the filtered text\n",
    "tokenized_reviews_series = pd.Series(filtered_texts).apply(lambda x: x.split())\n",
    "\n",
    "print(tokenized_reviews_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73263ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#de-tokenize the lemmatized reviews and plot the most common words.\n",
    "\n",
    "reviews_3 = []\n",
    "for i in range(len(tokenized_reviews_series)):\n",
    "    reviews_3.append(' '.join(tokenized_reviews_series[i]))\n",
    "\n",
    "df['reviews'] = reviews_3\n",
    "\n",
    "freq_words(df['reviews'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630bdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(tokenized_reviews_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8081450",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews_series]\n",
    "\n",
    "# Creating the object for LDA model using gensim library\n",
    "LDA = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=7, random_state=100,\n",
    "                chunksize=1000, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08543da",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbd3629",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews'][df[\"reviews\"].str.contains(\"please\")].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12578f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df[df['reviews'].str.contains(\"please\")][['Date', 'Content']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cef74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['reviews'].str.contains(\"need\")][['Date', 'Content']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d9e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['reviews'].str.contains(\"wrong\")][['Date', 'reviews']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['reviews'].str.contains(\"fast\")][['Date', 'Content']].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b8b990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3040f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "912e6293",
   "metadata": {},
   "source": [
    "## NLTK VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7295763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = SentimentIntensityAnalyzer()\n",
    "\n",
    "new_data[\"Positive\"] = [sentiments.polarity_scores(i)[\"pos\"] for i in new_data[\"Content\"]]\n",
    "new_data[\"Negative\"] = [sentiments.polarity_scores(i)[\"neg\"] for i in new_data[\"Content\"]]\n",
    "new_data[\"Neutral\"] = [sentiments.polarity_scores(i)[\"neu\"] for i in new_data[\"Content\"]]\n",
    "\n",
    "new_data.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.scatter(new_data.index, new_data[\"Negative\"], label='Negative', color='red')\n",
    "plt.scatter(new_data.index, new_data[\"Neutral\"], label='Neutral', color='blue', marker='x')\n",
    "plt.scatter(new_data.index, new_data[\"Positive\"], label='Positive', color='green')\n",
    "\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.xlabel('Reviews')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "avg_sentiments = new_data[[\"Positive\", \"Negative\", \"Neutral\"]].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bars = plt.bar(avg_sentiments.index, avg_sentiments.values, color=['green', 'red', 'blue'])\n",
    "\n",
    "plt.title('Average Sentiment Scores')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Average Score')\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.01, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "heatmap_data = new_data[[\"Positive\", \"Negative\", \"Neutral\"]]\n",
    "correlation_matrix = heatmap_data.corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, linewidths=1, linecolor='black')\n",
    "\n",
    "plt.title('Correlation Heatmap of Sentiment Scores')\n",
    "plt.show()\n",
    "\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#sns.countplot(x='Rating',data=new_data, palette='muted')\n",
    "\n",
    "#plt.xlabel('Rating')\n",
    "#plt.ylabel('Count')\n",
    "#plt.title('Count Plot of Ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96b0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfcd7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "425215ad",
   "metadata": {},
   "source": [
    "## Word2Vec + Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eefad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive : 1\n",
    "# Negative: -1\n",
    "# Neutral: 0\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "print(\"Number of rows per star rating:\")\n",
    "print(new_data['Rating'].value_counts())\n",
    "\n",
    "def map_sentiment(stars_received):\n",
    "    if stars_received <= 2:\n",
    "        return -1\n",
    "    elif stars_received == 3:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "new_data['Sentiment'] = [ map_sentiment(x) for x in new_data['Rating']]\n",
    "\n",
    "plt.figure()\n",
    "pd.value_counts(new_data['Sentiment']).plot.bar(title=\"Sentiment distribution in df\")\n",
    "plt.xlabel(\"Sentiment\")\n",
    "plt.ylabel(\"No. of rows in df\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd32386",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the stop words\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "new_data['Content'] = [ remove_stopwords(x) for x in new_data['Content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b361cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c55b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the text column to get the new column 'tokenized_text'\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "new_data['Tokenized Text'] = [simple_preprocess(line, deacc=True) for line in new_data['Content']]\n",
    "\n",
    "print(new_data['Tokenized Text'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e450a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stemmed_tokens\n",
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "new_data['Stemmed Tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in new_data['Tokenized Text'] ]\n",
    "\n",
    "new_data['Stemmed Tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac60fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4e39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split Function\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(new_data, test_size=0.3, shuffle_state=True):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split( new_data[['Date', 'Username', 'Content', 'Rating', 'Helped', 'Language','Tokenized Text', 'Stemmed Tokens']], \n",
    "                                                        new_data['Sentiment'], \n",
    "                                                        shuffle=shuffle_state,\n",
    "                                                        test_size=test_size, \n",
    "                                                        random_state=15)\n",
    "    \n",
    "    print(\"Value counts for Train sentiments\")\n",
    "    print(Y_train.value_counts())\n",
    "    print(\"Value counts for Test sentiments\")\n",
    "    print(Y_test.value_counts())\n",
    "    print(type(X_train))\n",
    "    print(type(Y_train))\n",
    "    X_train = X_train.reset_index()\n",
    "    X_test = X_test.reset_index()\n",
    "    Y_train = Y_train.to_frame()\n",
    "    Y_train = Y_train.reset_index()\n",
    "    Y_test = Y_test.to_frame()\n",
    "    Y_test = Y_test.reset_index()\n",
    "    print(X_train.head())\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# Call the train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = split_train_test(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "# Skip-gram model (sg = 1)\n",
    "\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "\n",
    "word2vec_model_file = r'C:\\Users\\Om Prakash Yadav\\Downloads' + 'word2vec_' + str(size) + '.model'\n",
    "start_time = time.time()\n",
    "stemmed_tokens = pd.Series(new_data['Stemmed Tokens']).values\n",
    "\n",
    "# Train the Word2Vec Model\n",
    "\n",
    "w2v_model = Word2Vec(stemmed_tokens, min_count = min_count, workers = workers, window = window, sg = sg)\n",
    "print(\"Time taken to train word2vec model: \" + str(time.time() - start_time))\n",
    "w2v_model.save(word2vec_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d32e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the model from the model file\n",
    "model = Word2Vec.load(word2vec_model_file)\n",
    "\n",
    "# Unique ID of the word\n",
    "print(\"Index of the word 'time':\")\n",
    "print(model.wv.key_to_index['time'])\n",
    "\n",
    "# Total number of the words \n",
    "print(len(model.wv.key_to_index))\n",
    "\n",
    "# Print the size of the word2vec vector for one word\n",
    "print(\"Length of the vector generated for a word\")\n",
    "print(len(model.wv['time']))\n",
    "\n",
    "# Get the mean for the vectors for an example review\n",
    "print(\"Print the length after taking average of all word vectors in a sentence:\")\n",
    "\n",
    "print(np.mean([model.wv[token] for token in new_data['Stemmed Tokens'][0]], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93eca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the vectors for train data in following file\n",
    "\n",
    "word2vec_filename = r'C:\\Users\\Om Prakash Yadav\\Downloads' + 'train_review_word2vec.csv'\n",
    "\n",
    "with open(word2vec_filename, 'w+') as word2vec_file:\n",
    "    for index, row in X_train.iterrows():\n",
    "        model_vector = (np.mean([model.wv[token] for token in row['Stemmed Tokens']], axis=0)).tolist()\n",
    "        if index == 0:\n",
    "            header = \",\".join(str(ele) for ele in range(1000))\n",
    "            word2vec_file.write(header)\n",
    "            word2vec_file.write(\"\\n\")\n",
    "            \n",
    "        # Check if the line exists else it is vector of zeros\n",
    "        if type(model_vector) is list:  \n",
    "            line1 = \",\".join( [str(vector_element) for vector_element in model_vector] )\n",
    "        else:\n",
    "            line1 = \",\".join([str(0) for i in range(1000)])\n",
    "        word2vec_file.write(line1)\n",
    "        word2vec_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#Import the DecisionTreeeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load from the filename\n",
    "word2vec_df = pd.read_csv(word2vec_filename)\n",
    "\n",
    "#Initialize the model\n",
    "clf_decision_word2vec = DecisionTreeClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model\n",
    "clf_decision_word2vec.fit(word2vec_df, Y_train['Sentiment'])\n",
    "print(\"Time taken to fit the model with word2vec vectors: \" + str(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a827379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "test_features_word2vec = []\n",
    "for index, row in X_test.iterrows():\n",
    "    model_vector = np.mean([model.wv[token] for token in row['Stemmed Tokens']], axis=0)\n",
    "    if type(model_vector) is list:\n",
    "        test_features_word2vec.append(model_vector)\n",
    "    else:\n",
    "        test_features_word2vec.append(np.array([0 for i in range(1000)]))\n",
    "test_predictions_word2vec = clf_decision_word2vec.predict(test_features_word2vec)\n",
    "print(classification_report(Y_test['Sentiment'],test_predictions_word2vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7a863",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    " \n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=new_data, x='Date', y='Rating', label='Rating', color='blue')\n",
    " \n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Rating of Bhashini Over Time')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = new_data.resample('M', on='Date').mean()  # Resampling to monthly frequency, using mean as an aggregation function\n",
    " \n",
    "sns.set(style=\"whitegrid\")\n",
    " \n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.lineplot(data=df_resampled, x='Date', y='Rating', label='Month wise rating', color='blue')\n",
    " \n",
    "plt.xlabel('Date (Monthly)')\n",
    "plt.ylabel('Rating')\n",
    "plt.title('Monthly Resampling')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b25cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
